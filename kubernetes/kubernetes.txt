---
Ресурсы:

// оф сайт
- [ ]
 


---
элементы документа 

[?] - информация потенциально для многократного использования
[!] - была ошибка, недочет, нашли решение 
[*] - важное контекстное примечание 
[#<имяТега>] - так можим выносить различного рода информацию, оставляя ссылку 

---
краткое описание 

- [kubernetes] это платформа для оркестрации docker контейнеров




1) разбираемся с основными понятиями
  - [ ] основной источник информации
  - (*) один из узлов кластера kubernetes является управляющим и управляет запуском
    и масштабированием контейнеров на всех остальных узлах
  - [ kubelet ] на каждом узле кластера установлен агент kubernetes -> kubelet
  - [ Node ] нода это машина в кластере Kubernates
  - [ kube-Proxy ] на каждой ноде запускается простой proxy-балансировщик
  - [ etcd ] тут хранится состояние мастера
  - [ kubectl ] это консольный клиент kubernetes
  - [ pod ] это минимальная единица для kubernetes, это набор из одного или 
    нескольких котейнеров, контейнеры тут имеют один адресс
    разделяют память и могут связываться через localhost
  - [ replica Set ] это единица определяющая сколько одинаковых подов(pod) запустить
  - [ deployment ] это обертка над (replica Set) чтобы иметь возможность 
    обнавлять поды в (replica Set) постепенно
    - Deployments являются рекоммендуемым способом организации создания и масштабирования подов.
  - [ Service ] это абстракция определяет набор подов(pod) и настройки балансировки
    - чтобы сделать доступным deployment мы должны иметь сервис, 
      который должны смапить через labels
  - [ Volumes ] это тома, этот функционал позволяет маунтить в контейнер директории


2) Configuration Best Practices
  - [ https://kubernetes.io/docs/concepts/configuration/overview/ ]
  - конфигурационные файлы писать на .yaml
  - пример конфигурации
    - [ https://github.com/kubernetes/examples/blob/master/guestbook/all-in-one/guestbook-all-in-one.yaml ]
  - не использовать голые поды (Pods), только в составе ReplicaSet или deployment


3) надо поднять кластер в облаке
  - [ https://www.youtube.com/watch?v=q7HTKiRQ6cg ] вебинар с практикой
  - [ https://youtu.be/L3tgJXsMUTU ] тоже хороший видосик 
  - надо зарегестрироваться в [ consol cloud google com ]



4) kubectl Консольный интерфейс
  - мы можем подключится и управлять кластером кубрнейтса
  - [ kubectl get nodes ] посмотреть все ноды
  - [ kubectl get pods ] посмотреть все поды
  - [ kubectl get deployments ] посмотреть все деплойменты
  - [ kubectl get services ] посмотреть все сервисы
  - [ kubectl get events ] посмотреть события кластера
  - [ kubectl config view ] посмотреть конфигурацию кластера 
  - [ kubectl get ingress ] посмотреть созданный ( kind: Ingress )
    - [!] IP address не показывается
      - подождать немного он появляется не сразу
    - [ kubectl get ing ] альтернативная команда
  - [ kubectl describe deployments ] смотрим информацию по деплойментам
  - [ kubectl create -f pod.yaml ] создаем под из файла
    - [ kubectl apply -f pod.yaml ] можем сделать изменения и не удаляя они применятся
  - [ kubectl delete -f pod.yaml ] удалить из куба то, что мы создали ранее
  - [ kubectl scale --replicas=2 replicaset my-replicaset ] команда для изменения числа реплик
  - [ kubectl describe под/реплика_сет/или еще что то ] выдаст информацию


5) Ingress
  - через эту сущность мы можем получить трафик из вне в кластер кубернетиса
  - (*) пример есть в этой папке в файле in
  - в запросе мы смотрим на [ host ] заголовок и определяем сервис получатель
    - также можно определить правила по url куда перенаправлять
  - С помощью этого API балансировщик нагрузки легко можно настроить на работу 
    с несколькими бэкенд-сервисами.
  - в Kubernetes существуют два типа сущностей: Ingress и IngressController.
  - (*) Слерм советует использовать [ Nginx ] -> [ kubernetes.io/ingress.class: "nginx" ]
  - для миникуба его надо включать (аддон)
    - [ minikube addons enable ingress ] 
  - Стандартно в Kubernetes использует Ingress контроллер на базе Nginx. 


6) deployment 
  - внутри запускается репликасет с подами, только теперь мы можем определить [ strategy ]
  - при обновлении создастся новый реплика сет в котором согласно стратекии 
    будут создаваться новые поды, а в старом репликасете гаситься.
    - старый реплика сет в деплойменте может пригодиться для отката назад
    - [ kubectl rollout undo deployment rolled back ]
    - [ revisionHistoryLimit ] сколько хранить старых версий
  - [ apiVersion ] версия версия api kubernates
    - [ apps/v1 ] - стабильная первая версия, есть рвзные виды API
  - [ Kind ] тип создаваемого обьекта, много разных
  - [ metadata ] можем определить [ labels, name, namespace, annotations ]
  - [ spec ] определяем спецефические настройки для обьекта
  - [ selector ] позволяет опрелить набор лейблов для обозначения,
     какие поды входят в этот деплоймент, чтобы менеджерить именно их
  - [ strategy ] позволяет указать стратегию обновления подов 


7) Cert-manager
  - утилита в кластере Kubernetes, которая умеет автоматически получать 
    и продлевать сертификаты от различных удостоверяющих центров


8) Аддоны (Addons)
  - [ https://minikube.sigs.k8s.io/docs/tasks/addons/ ]


9) Sealf-Healing и health cheack
  - шпаргалка
    - [ https://www.baeldung.com/spring-boot-kubernetes-self-healing-apps ]
  - [ readinessProbe ] определем что приложение готово работать после старта
  - [ livenessProbe ] определяем что приложение еще живое
    - общие параметры (задаются в секундах)
      - [ initialDelaySeconds ] сколько подождать перед запросом
      - [ timeoutSeconds ] сколько ждать ответа от сервиса
      - [ periodSeconds ] как часто делать запрос
      - [ failureThreshold ] сколько раз повторно попробовать, 
        чтобы точно сказать (задается в разах)

 
10) ConfigMap 
  - это способ замаунтить конфигурацинные файлы в деплоймент
  - (*) можно подключить как переменную окружения
  - при изменении данных в конфигмапе, эти дпнные также поменяются в контейнерах
    - (*) надо сказать приложению перечитать конфиг, если оно автоматически неперечитывает
  - полезные сайты
    - [ https://stackoverflow.com/questions/26140784/spring-boot-is-it-possible-to-use-external-application-properties-files-in-arbi ]
    - [ https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#boot-features-external-config-application-property-files ]


12) Secret
  - это тоже самое что и [ ConfigMap ] только для паролей/логинов/токены
  - тут есть только кодирование в [ base64 ] 
    любой кто получит эти данные сможет декодировать и получить информацию
  - (*) можно подключить как переменную окружения
  - на самом деле есть смысл только в связке с михонизмом разграничения прав
    для разных пользователей, чтобы пользователи могли смотреть [ ConfigMap ],
    а секреты [ Secret ] не сможет посмотреть  
  - есть три типа секретов [ Secret ]
    - [ generic ] для хранения паролей/токенов приложений
    - [ docker-registry ] для данных авторизации в docker regestry
    - [ tls ] для tls сертификатов для ingress



11) [ RBAC ] управление доступом на основе ролей
  - RBAC определяется тремя вещами:
    - [ Subjects ] совокупность пользователей и процессов, которые хотят иметь доступ в Kubernetes API;
      - пример:
        - [ User ] девелопер антон
        - [ User ] тестировщик миша
        - [ user ] процесс, живущий вне кластера
        - [ ServiceAccount ] процесс внутри кластера, запущенный на поде
    - [ Resources ] совокупность объектов Kubernetes API, доступных в кластере.
      - пример: [ Pods, Deployments, Services, Nodes, PersistentVolumes ]
    - [ Verbs ] совокупность операций, которые могут быть выполнены над ресурсами.
      - пример: [ get, watch, create, delete ]
  - ключевая концепция
    - Мы хотим соединить субъекты, ресурсы API и операции. 
      Другими словами, мы хотим указать для заданного пользователя, 
      какие операции могут быть исполнены на множестве ресурсов.


12) надо разобраться с сущностями [ kind ] в кубернетесе
  - [ Role ] соединяет ресурсы и глаголы. Надо посмотреть [ RBAC ]  
  - [ ClusterRole ] тоже что и [ Role ] только во всех простанствах имен
  - [ RoleBinding ] соединяют оставшиеся сущности-субъекты. Указав роль, 
    которая уже связывает объекты API с глаголами, теперь мы выбираем субъекты, 
    которые могут их использовать.
  - [ ClusterRoleBinding ] тоже что и [ RoleBinding ] только во всех простанствах имен
  - [ ConfigMap ]
  - [ Deployment ]
  - [ Ingress ]
  - [ NetworkPolicy ]
  - [ PodDisruptionBudget ] мы можем использовать, чтобы в любое время было доступен как минимум
    какое либо колличество подов имейющих определенный лейбл
  - [ PodSecurityPolicy ]
  - [ PersistentVolumeClaim ] позволяет удобно предоставлять дисковое пространство
  - [ Service ]
  - [ User ] глобальные пользователи, предназначены для людей или процессов, живущих вне кластера
  - [ ServiceAccount ] ограниченные пространством имён и предназначенные для процессов внутри кластера, 
    запущенных на подах. 
  - [ StatefulSet ] нужно использовать если нам важно сохранять связанные ресурсы 
    при переходе с ноды на ноду или падении/подьеме


13) Resources
  - ресурсы это CPU и память
  - (*) очень важно указать параметры ресурсов для всех компонентов, 
    чтобы кубернейтис понимал на какой ноде можно поднимать под, а на какой уже не хватет ресурсов
  - [ Limits ] уазываем верхнюю границу какого-то ресурса, если мы его привышаем, убиваем под
  - [ Requests ] указываем сколько ресурсов резервируем для пода
    - не делится с другими подами
  - [ cpu: 100m ] тут 10% cpu. Для указания ресурса прочессора используюся тысячные доли


14) Configure Quality of Service for Pods
  - так кубернейтис определяет какой из подов приоритетней,
    если надо выбирать какой из подов поднять, то выйграет тот,
    у которого указаны лимиты и резервирование.
  - [ https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/ ]
  - нужно создавать неймспейсы
  - [ Guaranteed ]
    - есть CPU и MEMORY [ Limits ] и [ request ] одинаковые значения
  - [ Burstable ]
    - есть CPU и MEMORY [ Limits ] и [ request ] лимиты больше резервируемых
  - [ BestEffort ]
    - нету лимитов и резервирования CPU и MEMORY [ Limits ] и [ request ]


15) Service
  - это сущность для определения куда направлять трафик (на какие поды по лейблу)
  - эта абстракция  под капотам реализована на [ ipvs или iptables ]
    - каждому сервису выдается статический ip адрес в рамках кластера
    - также при создании создается DNS запись
    - сервис это посути набор правил iptables или правил ipvs
    - за создание этих правил отвечает [ Kube-proxy ]
  - для отправки трафика на сервис можно обращаться по имени, так как 
    при создании сервиса содается запись в DNS, чтобы резолвить имена сервисов
  - (*) когда создается [ service ] автоматически еще создается [ endpoints ]
    в этой сущности находятся одреса подов куда надо слать прафик этим сервисов
  - в сервисе есть 
    - [ name ] имя сервиса
    - [ port ] порт на который принимаем трафик
    - [ targetport ] порт на который перенаправляем трафик
      - [ selector ] указываем тут лейбл подов, чтобы указать куда перенаправить трафик


16) PV/PVC
  - определяет как в кубернейтесе рабодать с хранилищами
    - мы бы хотели имели возможность рестартовать приложение и не терять данные
  - для хранения данных есть несколько абстракций
    - [ PV - PersistentVolume ] описывает постоянный том на котором будут данные
      - указываем размер тома
    - [ PVC - PersistentVolumeClaim ] запрос на подключение постоянного тома
      - указываем подключаемый том и его тип
      - [ storage class ] указываем права на доступ к данным
  - [ Provisioner ] это специальная программа в кубернейтесе которая может 
    создавать тома необходимого размера
 

17) Устройство kubernates кластера (компоненты кластера)
  - [ Etcd ] это хранилище в котором хранится вся информация о кластере
    - [ Etcdctl ] утилита управления кластером ETCD
    - рекомендации быстрые диски и стабильная сеть
  - [ API server ] через него мы управляем кластером, создать под удалить и тд.
    - работает по REST API
    - получая команду, делает изменение в [ Etcd ], получив подтверждение, возвращает ответ
    - [ kubectl ] это утилита, которая шлет HTTP запросы на [ API server ]
  - [ Controller-manager ] это набор контроллеров которые контролируют кластер
    - почти на каждую абстракцию кубернейтиса есть свой контроллер для управления
    - смотрит через [ API server ] есть ли изменения, нужно ли что то сделать (подписан на события)
    - [ Node Controller ], [ Replication Controller ], [ Endpoints Controller ] и другие
    - [ GarbageCollector ]  сборщик мусора
  - [ Sheduler ] отвечает за назначение запуск подов на нодах
    - смотрит через [ API server ] есть ли изменения, нужно ли что то сделать (подписан на события)
    - при принятии решения учитывает:
      - [ QoS ] это три класа приоритета в зависимости как выставлены лимиты и запросы
      - [ Affinity / anti-Affinity ] набор правил где лучше запустить под
      - [ Requested Resources ] запрос у пода по памяти и процессору
      - [ PriorityClass ] можем указать приоритеты для подов, какие запускать в первую очередь
  - [ Kubelet ] это приложение запущенное на каждой ноде кластера, оно выполняет команды
    - единственный компонент который не работает в докере, отдает команды [ Docker daemon ]
    - идет смотрит в папку, где лежит манифест с основными мастеровыми компанентами
      [ API server, Etcd, Controller-manager, Sheduler ] и запускает. Это static pods
    - создает поды (передает команды докер деману на запуск контейнеров)
    - делает пробы
    - следит за свободным местом
    - смотрит через [ API server ] есть ли изменения, нужно ли что то сделать (подписан на события)
  - [ Kube-proxy ] управляет сетевыми правилами на нодах
    - стоит на каждой ноде
    - смотрит через [ API server ] есть ли изменения, нужно ли что то сделать (подписан на события)   
    - фактически реализует абстракцию [ service ]
    - у нас есть два варианта реализации сервиса [ ipvs и iptables ]
    - 


18) Network (сеть)
  - у каждого пода свой сетевой неймспейс (подсеть ноды)
  - у каждой ноды свой сетевой неймспейс (подсеть кластера)
  - у кластера свой неймспейс
  - есть разные сетевые плагины дающие разную функциональность
    - [ Flannel ] сетевой плагин управляет правилами роутинга, раздает корректно подсети
    - [ Calico ] добавляет управление политиками доступа 
    - есть какой-то предлогающий шифрование


19) отказоустойчивый сетап кластера
  - в продакшене нужно исполь зовать как минимум трех мастеровый кластер
  - для работы с [ etcd ] ничего дополнительно делать не надо, 
    только три мастера запустть и быстрые диски ихорошая сеть.
  - с [ API server ] нет проблем
  - у [ Controller Manager ] и [ Scheduler ] реализована работа с одним мастером а все ост рабы
    - не нужно что то делать дополнительно
  - с [ Kubelet ] и [ Kubeproxy ] есть проблемы, так как на ноде
    они умеют ходить только в локальный [ API Server ]
  - (*) слерм ставит [ Ingress-Controller ] в отдельную виртуалку для безопасности и 
    чтобы при падении виртуалки с подами [ Ingress ] продолжал работать








[?] как выполнить команду на поде 
  - [ kubectl exec <имя пода> -it bash ]

[?] как посмотреть правила [ iptables ]
  - [  iptables -t nat -S ] вывести набор правил

[?] как посмотреть запросы от kubectl
  - добавляем ключ с уровнем логирования к команде [ --v=8 ]

[?] как удобно посмотреть DNS запись в [ kubernetes ]
  - [ nslookup  имя_сервиса ]
  - (*) для обращения к сервису в другом неймспесе надо использовать полное имя

[?] как получить справку по сущностям кубернейтика
  - есть встроенный [ man ]
  - [ kubectl explain deployment/pod/replicaset/... ] получить инфу
  - [ kubectl explain deployment.spec ] (*) чтобы провалиться на уровень глубже идем через точку

[?] как в консоль добавить автодополнение для [ kubectl ]
  - [ kubectl completion -h ] посмотрим справку про автодополнение
  - [ vim ~/.zshrc ] добавим в файл две строчки
    - [ autoload -Uz compinit && compinit ]  
    - [ source <(kubectl completion zsh) ]  
  - [!] при запуске консоли видим сообщение
    - [ "Ignore insecure directories and files and continue [y] or abort compinit [n]?" ] 
    - (*) выполнить один раз в консоли
      - [ compaudit | xargs chmod g-w ] меняем права у директорий


 
 
// #nop
#----------------------------------------------- 

  [!] nop

#----------------------------------------------- 
 
