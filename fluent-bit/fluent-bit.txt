---
Ресурсы:

// оф сайт
- [ https://fluentbit.io/ ]
 


---
элементы документа 

[?] - информация потенциально для многократного использования
[!] - была ошибка, недочет, нашли решение 
[*] - важное контекстное примечание 
[#<имяТега>] - так можим выносить различного рода информацию, оставляя ссылку 

---
краткое описание 

- [ fluent-bit ] позволяет получать сообщения из разных источников обрабатывать/фильтровать и отправлять потребителям.
  Это многоплатформенный инструмент пересылки логов с открытым исходным кодом, 
  который призван стать универсальным швейцарским ножом для сбора и распространения логов.


1) устанавливаем
  - есть несколько вариантов
    - [ docker ] [ https://hub.docker.com/r/fluent/fluent-bit/ ]
      - (*) есть имеджы с тегом "*-debug", в них есть bash (содержит Busybox)
      - запустим "fluent-bit" конфикурацию input/output задаем ключами
      - [ docker run -ti fluent/fluent-bit:1.6 /fluent-bit/bin/fluent-bit -i cpu -o stdout -f 1 ]


2) концепции
  - [ Event or Record ]
    - каждое пришедшее сообщение будет содержать время прихода и само сообщение
    - время записывается как [ SECONDS.NANOSECONDS ]
  - [ Filtering ] 
    - есть много способов модифицировать сообщения или удалить
  - [ Tag ]
    - Каждому событию, которое попадает в Fluent Bit, назначается тег. 
      Этот тег представляет собой внутреннюю строку, 
      которая используется маршрутизатором на более позднем этапе, чтобы решить, 
      через какой этап фильтрации или вывода он должен пройти. 
  - [ Match ]
    - может быть несколько источников данных, разные шаги обработки для разных сообщений
      и разные потребители. "Math" представляет собой простое правило для выбора событий, 
      теги которых соответствуют определенному правилу.
  - [ Buffering ]
    - Существует внутреняя память, в которую сохраняются пришедшие сообщения перед обработкой и отправкой
    - Хранение данных по умолчанию в памяти, но можно хранить на диске
    - [ Backpressure ] - проблема когда на вход поступает данных больше чем мы можем отправить
      - Для решения этой проблемы есть механихм прекращения получения данных на вход,
        если наш внутренний буфер сообщений заполнен
  - [ Data Pipeline ]
    - [ Input ]
      - определяет способ получения данных
      - [ "Collectd", "CPU Metrics", "Disk I/O Metrics", "Docker Events", "Dummy", 
          "Exec", "Forward", "Head", "Health", "Kernel Logs", "Memory Metrics", 
          "MQTT", "Network I/O Metrics", "Process", "Random", "Serial Interface", 
          "Standard Input", "Syslog", "Systemd", "Tail", "TCP", "Thermal", "Windows Event Log ]
    - [ Parser ]
      - определяет способ получения данных
      - [ JSON", "Regular Expression", "LTSV", "Logfmt", "Decoders"]
    - [ Filter ]
      - определяет способ фильтрации данных 
      - [ "AWS Metadata", "Expect", "Grep", "Kubernetes", "Lua", "Parser", 
          "Record Modifier", "Rewrite Tag", "Standard Output", "Throttle", 
          "Nest", "Modify", "Tensorflow" ]
    - [ Buffer ]
      - храним данные перед отправкой в памяти, плюс можем хранить на диске
    - [ Router ]
      - При помощи "Tag" м "Match" определяем маршрут для сообщений
    - [ Output ]
      - определяет куда отправлять данные 
      - [ "Amazon CloudWatch", "Amazon Kinesis Data Firehose", "Amazon S3", "Azure", "Azure Blob", 
          "BigQuery", "Counter", "Datadog", "Elasticsearch", "File", "FlowCounter", "Forward", 
          "GELF", "HTTP", "InfluxDB", "Kafka", "Kafka REST Proxy", "LogDNA", "Loki", "NATS", 
          "New Relic", "NULL", "PostgreSQL", "Slack", "Stackdriver", "Standard Output", 
          "Splunk", "Syslog", "TCP & TLS", "Treasure Data" ]


3) конфигурационный файл
  - файл представляет собой набор пар ключ/значение, пары разбиты на секции
  - секции:
    - [SERVICE] это глобальные настройки для всех входов/выходов, фильтров и тд
    - [INPUT, FILTER, OUTPUT] остальные секции, которых может быть много
  - environment variables
    - [ ${MY_VARIABLE} ] в любом значении конфигмапы можно использовать 
    - (*) БАГА: в значении не должно быть пробелов 
      - [ https://github.com/fluent/fluent-bit/issues/1225 ]
  - команды
    - [ @INCLUDE ]
      - можно разбить конфиг файл на несколько файлов "@INCLUDE somefile.conf"
    - [ @SET ]
      - позволяет задать по умолчанию переменные среды "@SET my_input=cpu"
  - Upstream Servers
    - Это функциональность позволяющая выходному плагину слать сообщение на несколько серверов
  - Record Accessor
    - мега мощная функциональность, позволяющая делать запросы к JSON данным


4) мониторинг
  - https://docs.fluentbit.io/manual/administration/monitoring
  - есть поддержка метрик в формате Prometheus
  - есть дашборд для графаны






[?] как отправить JSON сообщение в TCP сокет
  - Запускаем "fluentbit" c "input: TCP" с портом "5175"
  - [ echo '{/"text/":/"value/"}' | nc localhost  5175 ]


[?] nop
  - nop

 
// #
#----------------------------------------------- 


#----------------------------------------------- 
 
