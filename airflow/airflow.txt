---
Ресурсы:

// оф сайт
- [ https://airflow.apache.org/ ] 
- [ https://github.com/apache/airflow ]


---
элементы документа 

[?] - информация потенциально для многократного использования
[!] - была ошибка, недочет, нашли решение 
[*] - важное контекстное примечание 
[#<имяТега>] - так можим выносить различного рода информацию, оставляя ссылку 

---
краткое описание 

- [ airflow ] is a platform created by the community to programmatically author, \
  schedule and monitor workflows.


1) Install 



5) Main Cconception
  - Info: The main characteristic of Airflow workflows is that 
    all workflows are defined in Python code. 
    “Workflows as code” serves several purposes:
    - "Dynamic": Airflow pipelines are configured as Python code, 
      allowing for dynamic pipeline generation.
    - "Extensible": The Airflow® framework contains operators to connect 
      with numerous technologies. 
      All Airflow components are extensible to easily adjust to your environment.
    - "Flexible": Workflow parameterization is built-in leveraging the Jinja templating engine.



10) DAG
  - [ DAG ] In Apache Airflow, stands for Directed Acyclic Graph


15) simplest example
- link: https://airflow.apache.org/docs/apache-airflow/stable/index.html
- [
from datetime import datetime

from airflow import DAG
from airflow.decorators import task
from airflow.operators.bash import BashOperator

# A DAG represents a workflow, a collection of tasks
with DAG(dag_id="demo", start_date=datetime(2022, 1, 1), schedule="0 0 * * *") as dag:
    # Tasks are represented as operators
    hello = BashOperator(task_id="hello", bash_command="echo hello")

    @task()
    def airflow():
        print("airflow")

    # Set dependencies between tasks
    hello >> airflow()
  ]





 



 


[?] nop
  - nop

 
 
// #c 
#----------------------------------------------- 

 

#----------------------------------------------- 
 
