---
Ресурсы:

// оф сайт
- [ https://mistral.ai/ ]
 


---
элементы документа 

[?] - информация потенциально для многократного использования
[!] - была ошибка, недочет, нашли решение 
[*] - важное контекстное примечание 
[#<имяТега>] - так можим выносить различного рода информацию, оставляя ссылку 

---
краткое описание 

- [ mistral.ai ] бесплатая нейронка для комерческого использования





1) Запускаем из Docker
  - [ https://docs.mistral.ai/self-deployment/vllm/ ]
  - устанавливаем значение для доступа к API 
    - [ HF_TOKEN=123 ] 
  - выполняем команду из описания
    - [
        docker run --gpus all \
          -e HF_TOKEN=$HF_TOKEN -p 8000:8000 \
          ghcr.io/mistralai/mistral-src/vllm:latest \
          --host 0.0.0.0 \
          --model mistralai/Mixtral-8x7B-Instruct-v0.1 \
          --tensor-parallel-size 2 # adapt to your GPUs \
          --load-format pt # needed since both `pt` and `safetensors` are available
      ]
  -...
  - идем на API
    - [ ]









[?] nop
  - nop

 
// #
#----------------------------------------------- 


#----------------------------------------------- 
 
