---
Ресурсы:

// оф сайт
- [ https://prometheus.io/ ]
 


---
элементы документа 

[?] - информация потенциально для многократного использования
[!] - была ошибка, недочет, нашли решение 
[*] - важное контекстное примечание 
[#<имяТега>] - так можим выносить различного рода информацию, оставляя ссылку 

---
краткое описание 

- [ prometheus ]  используется для сбора метрик приложения JVM 
и позволяет экспортировать данные в различные системы мониторинга.




1) запускаем локально из докера
  - [ docker run -p 9090:9090 prom/prometheus ] тестовый запуск
    - [ docker run -p 9090:9090 prom/prometheus:v2.17.1 ] запуск конкретной версии
    - [ http://localhost:9090/graph ] консоль промитеуса
  - есть инструкция по запуску в docker
    - [ https://prometheus.io/docs/prometheus/latest/installation/ ]
    - [ https://hub.docker.com/r/prom/prometheus ] докер хаб
  - создадим свой файл настроек [ prometheus.yml ]
  - так как будем стучаться в приложение из докер контейнера используем DNS [ host.docker.internal ]
    [
      global:
        scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
        evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.

      scrape_configs:
        - job_name: 'myapp'
          metrics_path: /application/prometheus
          static_configs:
            - targets: ['host.docker.internal:8080']
    ]
  - запускаем
    - [ docker run -p 9090:9090 -v $(pwd)/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus ]
 

2) Pushgateway
  - Это приложение, в которое мы можем пушить метрики, 
    чтобы промитеус потом пришел и забрал их
  - [ docker run -d -p 9091:9091 prom/pushgateway ] попробуем локально
  - [ https://github.com/prometheus/pushgateway ]
  - [ https://habr.com/ru/company/southbridge/blog/455290/ ]
  - helm chart
    - [ https://github.com/helm/charts/tree/master/stable/prometheus-pushgateway ]

  
3) как надежно собирать метрики
  - prometheus не масштабируется, можно самим сделать несколько инстансов 
    и разделить таргеты между инстансами
  - есть prometheus rederation, это мозволяет собирать метрики из промитеусов,
    таким образом можно строить иеарархию инстансов промитеусов.
  - обьем метрик ограничен одним сервером, но есть "remote_write" 
    это позволяет писать метрики во внешнее хранилише, например "Thanos + S3"


4) Thanos
  - предназначен для хранения большого числа метрик от prometheus
  - поддерживается разработчиками prometheus
  - хранит в "S3" хранилище, можно выбрать другое
  - обеспечивает qlobal query - храним метрики с кучи промитеусов 
    и делаем запрос по всем собранным метрикам 
  - поддерживает PromQl и Prometheus quering API
  -...
  - КОМПОНЕНТЫ:
    - "Thanos sidecar" устанавливается рядом с каждым prometheus 
      забирает данные из локального стореджа промитеуса в "S3"
      - [!] при использовании у промитеусов надо отключить [ data compaction ]
    - "Thanos store gateway" прослойка между "S3" и "Thanos quary"
    - "Thanos quary" реализует PromQl и Prometheus quering API
      - (*) есть web UI
      - [!] интересно что последнии 2ч метрик хранятся на промитеусах,
        поэтому "Thanos quary" делает запрос не только к "Thanos store gateway", но и 
        ко всем инстансам промитеуса 
        - сможет ли этот компонент достучаться до всех промитеусов ?
      - [!!] стоит подумать о бекапе метрик промитеусов
    - "Thanos compact" сжимает данные в "S3" 
    - "Thanos Ruler" выполняет правила "Alertmanager"
      - (*) есть web UI
  -...
  - могут отвалиться "Thanos sidecar"
  - "Thanos compact" может отвалиться из-за race'ов "Thanos sidecar"
  - "Thanos store gateway" может отдавать не консистентные данные из-за race'ов "Thanos sidecar"



8) Prometheus Operator 
  - https://github.com/prometheus-operator/prometheus-operator
  - provide kubernetes API like: 
    - PrometheusRule
      - 
      - [
          apiVersion: monitoring.coreos.com/v1
          kind: PrometheusRule
        ]
    - ServiceMonitor
      - It is used to configure Prometheus to scrape metrics from specific services running inside your Kubernetes cluster. 
        The ServiceMonitor CRD (Custom Resource Definition) allows you to specify which services should be scraped for metrics,
        how often they should be scraped, and how to configure the scraping process.
      - [
          apiVersion: monitoring.coreos.com/v1
          kind: ServiceMonitor
          metadata:
            name: example-servicemonitor
            namespace: monitoring
            labels:
              release: prometheus
          spec:
            selector:
              matchLabels:
                app: example-app
            endpoints:
              - port: http
                interval: 30s
                path: /metrics
                honorLabels: true
                scheme: http
            namespaceSelector:
              matchNames:
                - default
            jobLabel: example-job
        ]



[?] как сделать проверку [ readinessProbe , livenessProbe , health check ]
  - [ readinessProbe ] -> [ /-/ready ]
  - [ livenessProbe ] -> [ /-/healthy ]

[?] nop
  - nop

 
 
// #c 
#----------------------------------------------- 

 

#----------------------------------------------- 
 
